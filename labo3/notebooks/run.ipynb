{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34fc90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matias/dev/laboratorio3/labo3-2025v/labo3/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from multinational.config import ProjectConfig\n",
    "from multinational.dataset_generator import DatasetGenerator\n",
    "from multinational.models.lightgbm_regressor import LightGBMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac03b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"../project_config.yml\"\n",
    "config = ProjectConfig.from_yaml(config_path=config_path) # Can pass env vars if needed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf79b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-03 15:00:14.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.dataset_generator\u001b[0m:\u001b[36m_setup_mlflow_tracking\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1müîß Setting up MLflow tracking...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:15.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.utils\u001b[0m:\u001b[36mverify_mlflow_gcs_access\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mMLflow server is healthy and accessible\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:15.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.utils\u001b[0m:\u001b[36mcreate_mlflow_experiment_if_not_exists\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mUsing existing MLflow experiment: demand_forecasting_exp_5\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:15.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.dataset_generator\u001b[0m:\u001b[36m_setup_mlflow_tracking\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1m‚úÖ MLflow tracking setup completed\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:15.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.dataset_generator\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mRead and registered table 'sell_in'\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:15.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.dataset_generator\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mRead and registered table 'products'\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:15.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.dataset_generator\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mRead and registered table 'stocks'\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:16.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.dataset_generator\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mRead and registered table 'to_predict'\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:16.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.dataset_generator\u001b[0m:\u001b[36mgenerate_dataset\u001b[0m:\u001b[36m534\u001b[0m - \u001b[1müìÇ Dataset already generated for this experiment. Skipping generation.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run dataset_generation at: http://34.74.63.20:5000/#/experiments/5/runs/2900ac71f6d94cedb954cfaaaf976c74\n",
      "üß™ View experiment at: http://34.74.63.20:5000/#/experiments/5\n"
     ]
    }
   ],
   "source": [
    "generator = DatasetGenerator(config)\n",
    "generator.download_data()\n",
    "generator.generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dda96f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-03 15:00:18.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_setup_mlflow_tracking\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1müîß Setting up MLflow tracking...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:18.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.utils\u001b[0m:\u001b[36mverify_mlflow_gcs_access\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mMLflow server is healthy and accessible\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:18.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.utils\u001b[0m:\u001b[36mcreate_mlflow_experiment_if_not_exists\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mUsing existing MLflow experiment: demand_forecasting_exp_5\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:18.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_setup_mlflow_tracking\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1m‚úÖ MLflow tracking setup completed\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:18.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mprepare_features\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1müîÑ Starting feature preparation pipeline...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:00:18.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1müîÑ Loading data from MLflow...\u001b[0m\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [04:02<00:00, 242.51s/it]\n",
      "\u001b[32m2025-07-03 15:04:24.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1m‚úÖ Data successfully loaded from storage.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_identify_features\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1müîç Identifying feature types...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_identify_features\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mFound 2435 numeric features\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_identify_features\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mFound 5 categorical features\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_clip_extreme_values\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m‚úÇÔ∏è Clipping extreme values in dataset...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_clip_extreme_values\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mBefore clipping:\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_clip_extreme_values\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mDataset min: -1.02e+16\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_clip_extreme_values\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mDataset max: 4.29e+17\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_clip_extreme_values\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mAfter clipping:\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_clip_extreme_values\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mDataset min: -1.00e+06\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_clip_extreme_values\u001b[0m:\u001b[36m128\u001b[0m - \u001b[1mDataset max: 1.00e+06\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_clip_extreme_values\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1m‚úÖ Extreme values clipped successfully.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_flag_cherry_rows\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1müçí Cherry-flagging rows based on criteria...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_flag_cherry_rows\u001b[0m:\u001b[36m154\u001b[0m - \u001b[1m‚úÖ Cherry-flagging completed successfully.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_flag_cherry_rows\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mFound 24676 rows flagged as cherry, out of 28735 total rows.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_flag_problematic_standardization\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1müö© Flagging problematic standardization rows...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_flag_problematic_standardization\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1m‚úÖ Problematic standardization rows flagged.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_flag_problematic_standardization\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mFound 24752 rows with invalid standardization, out of 28735 total rows.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_encode_categorical_features\u001b[0m:\u001b[36m184\u001b[0m - \u001b[1müè∑Ô∏è Encoding categorical features...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_encode_categorical_features\u001b[0m:\u001b[36m200\u001b[0m - \u001b[1m‚úÖ Categorical features encoded successfully.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mprepare_features\u001b[0m:\u001b[36m213\u001b[0m - \u001b[1m‚úÖ Feature preparation pipeline completed.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36msplit_data\u001b[0m:\u001b[36m275\u001b[0m - \u001b[1müîÑ Splitting data...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36msplit_data\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mTraining dataset size: 3262\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36msplit_data\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTesting dataset size: 117\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36msplit_data\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mKaggle dataset size: 723\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_create_time_based_folds\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mCreated 5 time-based folds.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_create_time_based_folds\u001b[0m:\u001b[36m260\u001b[0m - \u001b[1mFold from 201703 to 201710 with 637 samples.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_create_time_based_folds\u001b[0m:\u001b[36m260\u001b[0m - \u001b[1mFold from 201711 to 201804 with 660 samples.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_create_time_based_folds\u001b[0m:\u001b[36m260\u001b[0m - \u001b[1mFold from 201805 to 201810 with 683 samples.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_create_time_based_folds\u001b[0m:\u001b[36m260\u001b[0m - \u001b[1mFold from 201811 to 201904 with 697 samples.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_create_time_based_folds\u001b[0m:\u001b[36m260\u001b[0m - \u001b[1mFold from 201905 to 201909 with 585 samples.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36msplit_data\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1m‚úÖ Data splitted successfully.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_setup_optuna_storage\u001b[0m:\u001b[36m333\u001b[0m - \u001b[1müîÑ Checking for existing Optuna study in GCS...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.gcs_manager\u001b[0m:\u001b[36m_get_gcs_client\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mDetected local environment - using service account file\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:24.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.gcs_manager\u001b[0m:\u001b[36m_get_gcs_client\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mLoading credentials from: /Users/matias/dev/laboratorio3/labo3-2025v/labo3/service-account.json\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:25.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_setup_optuna_storage\u001b[0m:\u001b[36m337\u001b[0m - \u001b[1m‚úÖ Downloaded existing Optuna study from GCS\u001b[0m\n",
      "[I 2025-07-03 15:04:27,733] Using an existing study with name 'demand_forecasting_study' instead of creating a new one.\n",
      "\u001b[32m2025-07-03 15:04:27.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36moptimize\u001b[0m:\u001b[36m527\u001b[0m - \u001b[1müîÑ Found 10 completed trials, running 0 more...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:27.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36moptimize\u001b[0m:\u001b[36m534\u001b[0m - \u001b[1m‚úÖ All trials already completed\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:27.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.gcs_manager\u001b[0m:\u001b[36mupload_file_from_memory\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mUploading file to gs://labo3_bucket/data/optuna_studies/optuna_study_demand_forecasting_exp_5.db\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:28.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.gcs_manager\u001b[0m:\u001b[36mupload_file_from_memory\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1m‚úÖ File uploaded successfully to gs://labo3_bucket/data/optuna_studies/optuna_study_demand_forecasting_exp_5.db\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:28.814\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36m_backup_study_to_gcs\u001b[0m:\u001b[36m353\u001b[0m - \u001b[34m\u001b[1müíæ Study backed up to GCS\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:28.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36moptimize\u001b[0m:\u001b[36m542\u001b[0m - \u001b[1mBest Optuna trial: 0\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:28.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36moptimize\u001b[0m:\u001b[36m543\u001b[0m - \u001b[1mBest CV AVG tfe: 0.9754893824811894\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:28.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36moptimize\u001b[0m:\u001b[36m544\u001b[0m - \u001b[1mBest parameters: {'learning_rate': 0.03574712922600244, 'num_leaves': 286, 'max_depth': 16, 'min_data_in_leaf': 6027, 'min_sum_hessian_in_leaf': 0.004207988669606638, 'bagging_fraction': 0.49359671220172163, 'bagging_freq': 1, 'feature_fraction': 0.9197056874649611, 'lambda_l1': 0.25378155082656645, 'lambda_l2': 0.6796578090758157, 'linear_lambda': 0.0012087541473056963, 'max_bin': 248}\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:30.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36moptimize\u001b[0m:\u001b[36m552\u001b[0m - \u001b[1mFinal model will use P75 of best iterations: 1\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:30.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36moptimize\u001b[0m:\u001b[36m580\u001b[0m - \u001b[1mFinal parameters: {'objective': 'regression', 'num_iterations': 1, 'learning_rate': 0.03574712922600244, 'num_leaves': 286, 'seed': 42, 'linear_tree': True, 'max_depth': 16, 'min_data_in_leaf': 6027, 'min_sum_hessian_in_leaf': 0.004207988669606638, 'bagging_fraction': 0.49359671220172163, 'bagging_freq': 1, 'bagging_seed': 42, 'feature_fraction': 0.9197056874649611, 'feature_fraction_seed': 42, 'lambda_l1': 0.25378155082656645, 'lambda_l2': 0.6796578090758157, 'linear_lambda': 0.0012087541473056963, 'verbosity': -1, 'max_bin': 248}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run lightgbm_optimization at: http://34.74.63.20:5000/#/experiments/5/runs/1b26c5b19e2a4c19bdc0e28d8308254b\n",
      "üß™ View experiment at: http://34.74.63.20:5000/#/experiments/5\n"
     ]
    }
   ],
   "source": [
    "model = LightGBMModel(config)\n",
    "model.prepare_features()\n",
    "model.split_data()\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e44c3f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-03 15:04:32.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m598\u001b[0m - \u001b[1müöÄ Starting final models training with optimized parameters...\u001b[0m\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.60it/s]\n",
      "\u001b[32m2025-07-03 15:04:35.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m633\u001b[0m - \u001b[1mLoaded existing model 1/10 with seed: 7271\u001b[0m\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.22it/s]\n",
      "\u001b[32m2025-07-03 15:04:37.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m649\u001b[0m - \u001b[1mLoaded existing feature importance for model 1/10 with seed: 7271\u001b[0m\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.92it/s]\n",
      "\u001b[32m2025-07-03 15:04:40.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m633\u001b[0m - \u001b[1mLoaded existing model 2/10 with seed: 861\u001b[0m\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.45it/s]\n",
      "\u001b[32m2025-07-03 15:04:42.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m649\u001b[0m - \u001b[1mLoaded existing feature importance for model 2/10 with seed: 861\u001b[0m\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.98it/s]\n",
      "\u001b[32m2025-07-03 15:04:45.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m633\u001b[0m - \u001b[1mLoaded existing model 3/10 with seed: 5391\u001b[0m\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.43it/s]\n",
      "\u001b[32m2025-07-03 15:04:48.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m649\u001b[0m - \u001b[1mLoaded existing feature importance for model 3/10 with seed: 5391\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:48.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mTraining final model 4/10 with seed: 5192\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:51.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mTraining final model 5/10 with seed: 5735\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:54.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mTraining final model 6/10 with seed: 6266\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:56.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mTraining final model 7/10 with seed: 467\u001b[0m\n",
      "\u001b[32m2025-07-03 15:04:59.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mTraining final model 8/10 with seed: 4427\u001b[0m\n",
      "\u001b[32m2025-07-03 15:05:01.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mTraining final model 9/10 with seed: 5579\u001b[0m\n",
      "\u001b[32m2025-07-03 15:05:03.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mTraining final model 10/10 with seed: 8323\u001b[0m\n",
      "\u001b[32m2025-07-03 15:05:05.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m737\u001b[0m - \u001b[1m‚úÖ Final models trained and logged successfully.\u001b[0m\n",
      "\u001b[32m2025-07-03 15:05:06.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m752\u001b[0m - \u001b[1m‚úÖ Logged aggregated feature importance for 2442 features\u001b[0m\n",
      "\u001b[32m2025-07-03 15:05:06.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m755\u001b[0m - \u001b[1mMaking predictions on test set...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:05:06.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m784\u001b[0m - \u001b[1mTotal Forecast Error on test set: 1.3466\u001b[0m\n",
      "\u001b[32m2025-07-03 15:05:07.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mtrain_final_ensemble\u001b[0m:\u001b[36m790\u001b[0m - \u001b[1m‚úÖ Final training completed and logged\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run final_lightgbm_models at: http://34.74.63.20:5000/#/experiments/5/runs/f63acd9019b646589ff230a1dd7e121c\n",
      "üß™ View experiment at: http://34.74.63.20:5000/#/experiments/5\n"
     ]
    }
   ],
   "source": [
    "model.train_final_ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbf533a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-03 15:34:09.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mpredict_for_kaggle\u001b[0m:\u001b[36m801\u001b[0m - \u001b[1müìä Making predictions for Kaggle submission...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:34:10.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mpredict_for_kaggle\u001b[0m:\u001b[36m804\u001b[0m - \u001b[1mRetrieving product IDs for Kaggle submission...\u001b[0m\n",
      "\u001b[32m2025-07-03 15:34:14.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mpredict_for_kaggle\u001b[0m:\u001b[36m879\u001b[0m - \u001b[1mKaggle submission file logged to MLflow: /var/folders/yf/r2bhztdn1nz1qpf_461fs9g00000gn/T/kaggle_submission.csv\u001b[0m\n",
      "\u001b[32m2025-07-03 15:34:14.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmultinational.models.lightgbm_regressor\u001b[0m:\u001b[36mpredict_for_kaggle\u001b[0m:\u001b[36m886\u001b[0m - \u001b[1m‚úÖ Kaggle submission completed successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run kaggle_predictions at: http://34.74.63.20:5000/#/experiments/5/runs/ab0230437d54421f94beaab5d8a4fc8f\n",
      "üß™ View experiment at: http://34.74.63.20:5000/#/experiments/5\n"
     ]
    }
   ],
   "source": [
    "model.predict_for_kaggle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multinational",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
