project:
  name: "multinational"
  version: "1.0.0"

experiment_name: "demand_forecasting_exp_6"

gcp:
  project_id: "labo3-464122"
  bucket_name: "labo3_bucket"
  zone: "us-east1-d"
  region: "us-east1"
  blob_path: "data"

orchestrator:
  vm_name: "node0"
  machine_type: "e2-standard-2"
  check_interval: 60  # seconds

repository:
  url: "https://github.com/MatiLarsson/labo3-2025v.git"
  branch: "main"

jobs:
  - name: "dataset"
    script: "run_dataset.py"
    instance_name: "dataset-worker"
    machine_type: "n1-highmem-16" # "n1-highmem-16" -> 16 CPU, 104GB RAM
    preemptible: true
    
  - name: "model"
    script: "run_model.py" 
    instance_name: "model-worker"
    machine_type: "n2-highmem-64" # "n2-highmem-64" -> 64 CPU, 512GB RAM
    preemptible: true
    depends_on: "dataset"

docker:
  orchestrator_image: "orchestrator:latest"
  worker_image: "worker:latest"

paths:
  data_files:
    - "data/product_id_to_predict_201912.txt"
    - "data/sell-in.txt"
    - "data/tb_productos.txt"
    - "data/tb_stocks.txt"

dataset_generation:
  testing_mode: true  # Set to false for full dataset in production
  max_lag_periods: 35
  anchored_ratios_periods: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]
  rolling_stats_window_sizes: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]
  rolling_statistics: ['mean', 'median', 'std', 'min', 'max', 'sum', 'count', 'variance', 'skewness', 'kurtosis']
  reg_slopes_window_sizes: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]
  max_z_lag_periods: 35
  z_anchored_delta_lag_periods: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]
  z_adjacent_delta_lag_periods: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]
  z_anchored_ratio_lag_periods: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]
  z_adjacent_ratio_lag_periods: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]
  z_regression_slopes_window_sizes: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]

model_dataset:
  stocks_file: "tb_stocks.txt"
  products_file: "tb_productos.txt"
  sell_in_file: "sell-in.txt"
  products_for_kaggle_file: "product_id_to_predict_201912.txt"
  target: "target"
  period: "periodo"
  cat_features:
    - cat1
    - cat2
    - cat3
    - brand
    - descripcion
  dataset_name: "dataset.parquet"
  clipping_threshold: 1e6  # Extreme value clipping threshold

strategy:
  test_month: 201910 # int
  kaggle_month: 201912 # int

testing_limits:
  testing_mode: true
  min_periodo: 201701
  max_customers: 50
  max_products: 20

cv:
  n_folds: 5

optimizer:
  study_name: "demand_forecasting_study"
  direction: "minimize"
  storage: null
  n_trials: 10

  param_ranges:
    learning_rate: [0.01, 0.3]  # log scale
    num_leaves: [10, 300]  # int
    max_depth: [3, 20]  # int
    min_data_in_leaf: [100, 10000]  # int
    min_sum_hessian_in_leaf: [0.001, 10]  # log scale
    bagging_fraction: [0.4, 1.0]  # float
    bagging_freq: [1, 7]  # int
    feature_fraction: [0.4, 1.0]  # float
    lambda_l1: [0.001, 10.0]  # log scale
    lambda_l2: [0.001, 10.0]  # log scale
    linear_lambda: [0.001, 10.0]  # log scale
    max_bin: [10, 255]  # int

  base_model_params:
    objective: 'regression'
    num_iterations: 9999 # Big enough to let early stopping work
    seed: 42
    linear_tree: True
    bagging_seed: 42
    feature_fraction_seed: 42
    verbosity: -1
    metric: 'custom'

final_train:
  num_seeds: 10